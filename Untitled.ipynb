{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51fff95-682b-4627-bbe5-a59e3aa40fa8",
   "metadata": {
    "id": "d51fff95-682b-4627-bbe5-a59e3aa40fa8",
    "tags": []
   },
   "source": [
    "# Importing and Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a89d9f0-d52c-4fa9-ad0b-869b77b1edbc",
   "metadata": {
    "id": "3a89d9f0-d52c-4fa9-ad0b-869b77b1edbc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e895ccb4-66ae-4415-b607-d15d7a694e00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "e895ccb4-66ae-4415-b607-d15d7a694e00",
    "outputId": "be1e9938-6167-41f9-bba2-562151ed41ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>1.5250</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>28.973189</td>\n",
       "      <td>12.728926</td>\n",
       "      <td>6.647958</td>\n",
       "      <td>8.348928</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>10.418441</td>\n",
       "      <td>4.521745</td>\n",
       "      <td>2.324659</td>\n",
       "      <td>3.401940</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>1.3875</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>24.777463</td>\n",
       "      <td>11.339800</td>\n",
       "      <td>5.556502</td>\n",
       "      <td>6.662133</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>1.4125</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>50.660556</td>\n",
       "      <td>20.354941</td>\n",
       "      <td>10.991839</td>\n",
       "      <td>14.996885</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>23.289114</td>\n",
       "      <td>11.977664</td>\n",
       "      <td>4.507570</td>\n",
       "      <td>5.953395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74046</th>\n",
       "      <td>F</td>\n",
       "      <td>1.6625</td>\n",
       "      <td>1.2625</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>50.660556</td>\n",
       "      <td>20.680960</td>\n",
       "      <td>10.361742</td>\n",
       "      <td>12.332033</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74047</th>\n",
       "      <td>I</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>10.446791</td>\n",
       "      <td>4.323299</td>\n",
       "      <td>2.296310</td>\n",
       "      <td>3.543687</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74048</th>\n",
       "      <td>F</td>\n",
       "      <td>1.4875</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>29.483480</td>\n",
       "      <td>12.303683</td>\n",
       "      <td>7.540967</td>\n",
       "      <td>8.079607</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74049</th>\n",
       "      <td>I</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>16.768729</td>\n",
       "      <td>8.972617</td>\n",
       "      <td>2.919999</td>\n",
       "      <td>4.280774</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74050</th>\n",
       "      <td>I</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>5.386405</td>\n",
       "      <td>2.055339</td>\n",
       "      <td>1.034757</td>\n",
       "      <td>1.700970</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74051 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height     Weight  Shucked Weight  \\\n",
       "id                                                               \n",
       "0       I  1.5250    1.1750  0.3750  28.973189       12.728926   \n",
       "1       I  1.1000    0.8250  0.2750  10.418441        4.521745   \n",
       "2       M  1.3875    1.1125  0.3750  24.777463       11.339800   \n",
       "3       F  1.7000    1.4125  0.5000  50.660556       20.354941   \n",
       "4       I  1.2500    1.0125  0.3375  23.289114       11.977664   \n",
       "...    ..     ...       ...     ...        ...             ...   \n",
       "74046   F  1.6625    1.2625  0.4375  50.660556       20.680960   \n",
       "74047   I  1.0750    0.8625  0.2750  10.446791        4.323299   \n",
       "74048   F  1.4875    1.2000  0.4125  29.483480       12.303683   \n",
       "74049   I  1.2125    0.9625  0.3125  16.768729        8.972617   \n",
       "74050   I  0.9125    0.6750  0.2000   5.386405        2.055339   \n",
       "\n",
       "       Viscera Weight  Shell Weight  Age  \n",
       "id                                        \n",
       "0            6.647958      8.348928    9  \n",
       "1            2.324659      3.401940    8  \n",
       "2            5.556502      6.662133    9  \n",
       "3           10.991839     14.996885   11  \n",
       "4            4.507570      5.953395    8  \n",
       "...               ...           ...  ...  \n",
       "74046       10.361742     12.332033   10  \n",
       "74047        2.296310      3.543687    6  \n",
       "74048        7.540967      8.079607   10  \n",
       "74049        2.919999      4.280774    8  \n",
       "74050        1.034757      1.700970    6  \n",
       "\n",
       "[74051 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv',index_col = 'id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84717a1d-d865-4adf-a38c-678072c4e636",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84717a1d-d865-4adf-a38c-678072c4e636",
    "outputId": "a887356b-d7a7-47bb-b26f-47d52e2bf71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 74051 entries, 0 to 74050\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Sex             74051 non-null  object \n",
      " 1   Length          74051 non-null  float64\n",
      " 2   Diameter        74051 non-null  float64\n",
      " 3   Height          74051 non-null  float64\n",
      " 4   Weight          74051 non-null  float64\n",
      " 5   Shucked Weight  74051 non-null  float64\n",
      " 6   Viscera Weight  74051 non-null  float64\n",
      " 7   Shell Weight    74051 non-null  float64\n",
      " 8   Age             74051 non-null  int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c07ee4-b17c-4a27-98a8-a270e6efca63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5c07ee4-b17c-4a27-98a8-a270e6efca63",
    "outputId": "0c520fa5-d747-4d22-9e7f-ed410e9c0950"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex               0\n",
       "Length            0\n",
       "Diameter          0\n",
       "Height            0\n",
       "Weight            0\n",
       "Shucked Weight    0\n",
       "Viscera Weight    0\n",
       "Shell Weight      0\n",
       "Age               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9e640b-5448-4730-a41e-8e1cb309cfea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "0d9e640b-5448-4730-a41e-8e1cb309cfea",
    "outputId": "4602157a-ea77-4cb2-e2aa-01ff5fd7a074"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74051.000000</td>\n",
       "      <td>74051.000000</td>\n",
       "      <td>74051.000000</td>\n",
       "      <td>74051.000000</td>\n",
       "      <td>74051.000000</td>\n",
       "      <td>74051.000000</td>\n",
       "      <td>74051.000000</td>\n",
       "      <td>74051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.317460</td>\n",
       "      <td>1.024496</td>\n",
       "      <td>0.348089</td>\n",
       "      <td>23.385217</td>\n",
       "      <td>10.104270</td>\n",
       "      <td>5.058386</td>\n",
       "      <td>6.723870</td>\n",
       "      <td>9.967806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.287757</td>\n",
       "      <td>0.237396</td>\n",
       "      <td>0.092034</td>\n",
       "      <td>12.648153</td>\n",
       "      <td>5.618025</td>\n",
       "      <td>2.792729</td>\n",
       "      <td>3.584372</td>\n",
       "      <td>3.175189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056699</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>13.437663</td>\n",
       "      <td>5.712424</td>\n",
       "      <td>2.863300</td>\n",
       "      <td>3.968930</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.075000</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>23.799405</td>\n",
       "      <td>9.908150</td>\n",
       "      <td>4.989512</td>\n",
       "      <td>6.931453</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.537500</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>32.162508</td>\n",
       "      <td>14.033003</td>\n",
       "      <td>6.988152</td>\n",
       "      <td>9.071840</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.012815</td>\n",
       "      <td>1.612500</td>\n",
       "      <td>2.825000</td>\n",
       "      <td>80.101512</td>\n",
       "      <td>42.184056</td>\n",
       "      <td>21.545620</td>\n",
       "      <td>28.491248</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Length      Diameter        Height        Weight  Shucked Weight  \\\n",
       "count  74051.000000  74051.000000  74051.000000  74051.000000    74051.000000   \n",
       "mean       1.317460      1.024496      0.348089     23.385217       10.104270   \n",
       "std        0.287757      0.237396      0.092034     12.648153        5.618025   \n",
       "min        0.187500      0.137500      0.000000      0.056699        0.028349   \n",
       "25%        1.150000      0.887500      0.300000     13.437663        5.712424   \n",
       "50%        1.375000      1.075000      0.362500     23.799405        9.908150   \n",
       "75%        1.537500      1.200000      0.412500     32.162508       14.033003   \n",
       "max        2.012815      1.612500      2.825000     80.101512       42.184056   \n",
       "\n",
       "       Viscera Weight  Shell Weight           Age  \n",
       "count    74051.000000  74051.000000  74051.000000  \n",
       "mean         5.058386      6.723870      9.967806  \n",
       "std          2.792729      3.584372      3.175189  \n",
       "min          0.042524      0.042524      1.000000  \n",
       "25%          2.863300      3.968930      8.000000  \n",
       "50%          4.989512      6.931453     10.000000  \n",
       "75%          6.988152      9.071840     11.000000  \n",
       "max         21.545620     28.491248     29.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e692c65-5040-402c-98aa-2f422c0d739a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "d8ff196b-ca7e-4957-bdeb-3a20ab8ed591",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a9b23747-d0a4-41a5-c34f-17efbb50bdb4",
    "tags": []
   },
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(df.corr(), text_auto=True, aspect=\"auto\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kMtnQsZHyT_1",
   "metadata": {
    "id": "kMtnQsZHyT_1"
   },
   "source": [
    "We can see that these are Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2438a6-fe90-4e1b-984f-46f406f3c543",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "WtBSRZq07Efw",
    "outputId": "1a88a7cb-00f9-4596-ef25-a5ce6b738305"
   },
   "source": [
    "px.histogram(df,'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hhF7uaQi8j-c",
   "metadata": {
    "id": "hhF7uaQi8j-c"
   },
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "r320zX0Q8mIl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r320zX0Q8mIl",
    "outputId": "4eae0abd-e034-4465-82cf-db54a959d3fd"
   },
   "outputs": [],
   "source": [
    "df['Sex'] = df['Sex'].map({'M' : 1,  'I':2, 'F':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "_lPU_hD_8mND",
   "metadata": {
    "id": "_lPU_hD_8mND"
   },
   "outputs": [],
   "source": [
    "y = df.pop('Age')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to your data\n",
    "scaler.fit(df)\n",
    "\n",
    "# Perform the MinMax scaling and convert to DataFrame\n",
    "X = pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "tb ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7Umxss9NPi",
   "metadata": {
    "id": "ae7Umxss9NPi",
    "tags": []
   },
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vBC9kuV58mQ7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBC9kuV58mQ7",
    "outputId": "847bd54c-e672-4ea0-b1fe-dfa1a89e6ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6438687763992075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear regression model\n",
    "modelLR = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelLR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelLR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 1, 'Model': 'LinearRegression', 'Accuracy':mseL}\n",
    "tb['LinearRegression'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9clz7G-W9SUW",
   "metadata": {
    "id": "9clz7G-W9SUW",
    "tags": []
   },
   "source": [
    "## [PolynomialFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "NSes-jE28mUO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSes-jE28mUO",
    "outputId": "24aded5c-bd4e-4303-eb4c-94a3208cbbc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.301580752639548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create an instance of PolynomialFeatures with the desired degree\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# Transform the feature dataset to include polynomial features\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# Create an instance of the regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the augmented feature dataset and the target variable\n",
    "model.fit(X_poly, y_train)\n",
    "\n",
    "# Make predictions using the augmented feature dataset\n",
    "X_polyT = poly.fit_transform(X_test)\n",
    "y_pred = model.predict(X_polyT)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(rmse)\n",
    "tb['PolynomialFeatures'] = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slfzPNUT9TRn",
   "metadata": {
    "id": "slfzPNUT9TRn",
    "tags": []
   },
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "NW9C31T99TaX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NW9C31T99TaX",
    "outputId": "bcd32041-c472-4488-8710-e4f40379ab1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.644834308184121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create a ridge regression model\n",
    "modelR = Ridge(alpha=0.5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 3, 'Model': 'Ridge', 'Accuracy':mseL}\n",
    "\n",
    "print(mseL)\n",
    "tb['Ridge'] = mseL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3Y2df569Th-",
   "metadata": {
    "id": "s3Y2df569Th-",
    "tags": []
   },
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "LmZmegty9TrE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmZmegty9TrE",
    "outputId": "179801c8-a055-42f5-e5ab-19dcd03025fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.409514974338962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create a lasso regression model\n",
    "modelLA = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelLA.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelLA.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID':4, 'Model': 'lasso', 'Accuracy':mseL}\n",
    "tb['lasso'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8FP1fPpS9TxF",
   "metadata": {
    "id": "8FP1fPpS9TxF",
    "tags": []
   },
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tfu2rumh9T31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfu2rumh9T31",
    "outputId": "b4f07744-6764-4df3-8d73-0779e0e00069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.93300346181345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Create an ElasticNet regression model\n",
    "modelEN = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelEN.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelEN.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 5, 'Model': 'ElasticNet', 'Accuracy':mseL}\n",
    "tb['ElasticNet'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M7pFjRXa9UK4",
   "metadata": {
    "id": "M7pFjRXa9UK4",
    "tags": []
   },
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "_2T85d9B9URB",
   "metadata": {
    "id": "_2T85d9B9URB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.514077374924042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create a decision tree regression model\n",
    "modelDTR = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelDTR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelDTR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 7, 'Model': 'DecisionTreeRegressor', 'Accuracy':mseL}\n",
    "tb[ 'DecisionTreeRegressor'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-svPhUFZ9UZB",
   "metadata": {
    "id": "-svPhUFZ9UZB",
    "tags": []
   },
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "S7suPUi19Ufq",
   "metadata": {
    "id": "S7suPUi19Ufq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.356784191331612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a random forest regression model\n",
    "modelRFR = RandomForestRegressor(n_estimators = 800)\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelRFR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelRFR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 8, 'Model': 'RandomForestRegressor', 'Accuracy':mseL}\n",
    "tb[ 'RandomForestRegressor'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZyHLbRro9yBP",
   "metadata": {
    "id": "ZyHLbRro9yBP",
    "tags": []
   },
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "iNtI5zpk9x3_",
   "metadata": {
    "id": "iNtI5zpk9x3_"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create a gradient boosting regression model\n",
    "\n",
    "modelGBR = GradientBoostingRegressor(n_estimators = 800)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "modelGBR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelGBR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 9, 'Model': 'GradientBoostingRegressor', 'Accuracy':mseL}\n",
    "tb[ 'GradientBoostingRegressor'] = mseL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YfB0H8bD-HEC",
   "metadata": {
    "id": "YfB0H8bD-HEC",
    "tags": []
   },
   "source": [
    "## BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "KmFvAt2Y-HJS",
   "metadata": {
    "id": "KmFvAt2Y-HJS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.643900746833225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Create a Bayesian Ridge regression model\n",
    "modelbr = BayesianRidge()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelbr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelbr.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 12, 'Model': 'BayesianRidge', 'Accuracy':mseL}\n",
    "tb[ 'BayesianRidge'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lzzizKUW-HO1",
   "metadata": {
    "id": "lzzizKUW-HO1",
    "tags": []
   },
   "source": [
    "## PassiveAggressiveRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aNKHfEYj-HVG",
   "metadata": {
    "id": "aNKHfEYj-HVG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.953226743474952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "# Create a Passive Aggressive regression model\n",
    "modelPAR = PassiveAggressiveRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelPAR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelPAR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 13, 'Model': 'PassiveAggressiveRegressor', 'Accuracy':mseL}\n",
    "tb[ 'PassiveAggressiveRegressor'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GZZLSDh2-Hb3",
   "metadata": {
    "id": "GZZLSDh2-Hb3",
    "tags": []
   },
   "source": [
    "## OrthogonalMatchingPursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "yq-mfPe1-Hgh",
   "metadata": {
    "id": "yq-mfPe1-Hgh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.24413119272728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "\n",
    "# Create an Orthogonal Matching Pursuit regression model\n",
    "modelOMP = OrthogonalMatchingPursuit()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelOMP.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelOMP.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 14, 'Model': 'OrthogonalMatchingPursuit', 'Accuracy':mseL}\n",
    "tb[ 'OrthogonalMatchingPursuit'] = mseL\n",
    "\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lyp9VkX9-Hlp",
   "metadata": {
    "id": "Lyp9VkX9-Hlp",
    "tags": []
   },
   "source": [
    "## RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "svpY8Xem-HrI",
   "metadata": {
    "id": "svpY8Xem-HrI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.6810809790051255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a RANSAC regression model\n",
    "ransac = RANSACRegressor(LinearRegression(), min_samples=5, residual_threshold=0.5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "ransac.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = ransac.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 15, 'Model': 'RANSACRegressor', 'Accuracy':mseL}\n",
    "tb[ 'RANSACRegressor'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BaJ8JHEH-HwU",
   "metadata": {
    "id": "BaJ8JHEH-HwU",
    "tags": []
   },
   "source": [
    "## HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04x9F7cO-H0z",
   "metadata": {
    "id": "04x9F7cO-H0z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.795631576242048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Varun Chindage\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# Create a Huber regression model\n",
    "modelHR = HuberRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelHR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelHR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 16, 'Model': 'HuberRegressor', 'Accuracy':mseL}\n",
    "tb[ 'HuberRegressor'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ydC_-Aha-H5o",
   "metadata": {
    "id": "ydC_-Aha-H5o",
    "tags": []
   },
   "source": [
    "## TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dWkoBP63-H-J",
   "metadata": {
    "id": "dWkoBP63-H-J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.705804062162434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "# Create a Theil-Sen regression model\n",
    "modelTSR = TheilSenRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelTSR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelTSR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 17, 'Model': 'TheilSenRegressor', 'Accuracy':mseL}\n",
    "tb[ 'TheilSenRegressor'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dEy_Kuit-IDO",
   "metadata": {
    "id": "dEy_Kuit-IDO",
    "tags": []
   },
   "source": [
    "## ARDRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6J0Vj8w-IHt",
   "metadata": {
    "id": "b6J0Vj8w-IHt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.644759225794523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "# Create an ARD regression model\n",
    "modelAR = ARDRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelAR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelAR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 18, 'Model': 'ARDRegression', 'Accuracy':mseL}\n",
    "tb['ARDRegression'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H2LGNwOi-wnh",
   "metadata": {
    "id": "H2LGNwOi-wnh",
    "tags": []
   },
   "source": [
    "## PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "RYAbtT0o-wyr",
   "metadata": {
    "id": "RYAbtT0o-wyr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.295321045169131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "# Create a Passive Aggressive classifier regression model\n",
    "modelPAC = PassiveAggressiveClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelPAC.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelPAC.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 19, 'Model': 'PassiveAggressiveClassifier', 'Accuracy':mseL}\n",
    "tb['ARDRegrPassiveAggressiveClassifieression'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meyIGuq3-w6b",
   "metadata": {
    "id": "meyIGuq3-w6b",
    "tags": []
   },
   "source": [
    "## PoissonRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "H-QQeJWe-xAu",
   "metadata": {
    "id": "H-QQeJWe-xAu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.15210770184293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "# Create a Poisson regression model\n",
    "modelPR = PoissonRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelPR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelPR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 20, 'Model': 'PoissonRegressor', 'Accuracy':mseL}\n",
    "tb['PoissonRegressor'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1XFvDLp0-xQD",
   "metadata": {
    "id": "1XFvDLp0-xQD",
    "tags": []
   },
   "source": [
    "## Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "LaPNxpVC-xU5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LaPNxpVC-xU5",
    "outputId": "20231183-0a89-4830-dacc-3d92a4062e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.64386877639921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lars\n",
    "\n",
    "# Create a LARS regression model\n",
    "modelLAR = Lars()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelLAR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelLAR.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 22, 'Model': 'Lars', 'Accuracy':mseL}\n",
    "tb['Lars'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GZ4UM6bL-xaH",
   "metadata": {
    "id": "GZ4UM6bL-xaH",
    "tags": []
   },
   "source": [
    "## RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3pvLtGpm-xfE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pvLtGpm-xfE",
    "outputId": "ad0af17c-7cd2-4a96-eaee-f5a4fda02c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.64402220125446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Create a RidgeCV regression model\n",
    "modelRC = RidgeCV()\n",
    "\n",
    "# Fit the model to the training data\n",
    "modelRC.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = modelRC.predict(X_test)\n",
    "mseL = mean_squared_error(y_test, predictions)\n",
    "new_row = {'ID': 23, 'Model': 'RidgeCV', 'Accuracy':mseL}\n",
    "tb['RidgeCV'] = mseL\n",
    "print(mseL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26ae12-f956-4e25-a939-5b83f3927220",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "883732e5-f066-4025-8600-4316c41da868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 10.4357\n",
      "Epoch 2/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 5.4457\n",
      "Epoch 3/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.8319\n",
      "Epoch 4/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.6468\n",
      "Epoch 5/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5984\n",
      "Epoch 6/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5711\n",
      "Epoch 7/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5491\n",
      "Epoch 8/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5337\n",
      "Epoch 9/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5181\n",
      "Epoch 10/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5083\n",
      "Epoch 11/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4920\n",
      "Epoch 12/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4849\n",
      "Epoch 13/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4693\n",
      "Epoch 14/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4701\n",
      "Epoch 15/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4622\n",
      "Epoch 16/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4573\n",
      "Epoch 17/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4516\n",
      "Epoch 18/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4450\n",
      "Epoch 19/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4405\n",
      "Epoch 20/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4332\n",
      "Epoch 21/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4303\n",
      "Epoch 22/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4293\n",
      "Epoch 23/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4289\n",
      "Epoch 24/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4245\n",
      "Epoch 25/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4216\n",
      "Epoch 26/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4147\n",
      "Epoch 27/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4166\n",
      "Epoch 28/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4151\n",
      "Epoch 29/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4097\n",
      "Epoch 30/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4097\n",
      "Epoch 31/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4094\n",
      "Epoch 32/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4096\n",
      "Epoch 33/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4060\n",
      "Epoch 34/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4039\n",
      "Epoch 35/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4039\n",
      "Epoch 36/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4020\n",
      "Epoch 37/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4007\n",
      "Epoch 38/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4011\n",
      "Epoch 39/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3988\n",
      "Epoch 40/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3977\n",
      "Epoch 41/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3948\n",
      "Epoch 42/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3973\n",
      "Epoch 43/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3961\n",
      "Epoch 44/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3929\n",
      "Epoch 45/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3909\n",
      "Epoch 46/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3952\n",
      "Epoch 47/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3922\n",
      "Epoch 48/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3898\n",
      "Epoch 49/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3894\n",
      "Epoch 50/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3864\n",
      "Epoch 51/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3921\n",
      "Epoch 52/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3893\n",
      "Epoch 53/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3925\n",
      "Epoch 54/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3882\n",
      "Epoch 55/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3846\n",
      "Epoch 56/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3855\n",
      "Epoch 57/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3795\n",
      "Epoch 58/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3912\n",
      "Epoch 59/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3785\n",
      "Epoch 60/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3846\n",
      "Epoch 61/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3791\n",
      "Epoch 62/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3813\n",
      "Epoch 63/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3782\n",
      "Epoch 64/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3831\n",
      "Epoch 65/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3759\n",
      "Epoch 66/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3830\n",
      "Epoch 67/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3769\n",
      "Epoch 68/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3799\n",
      "Epoch 69/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3746\n",
      "Epoch 70/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3732\n",
      "Epoch 71/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3824\n",
      "Epoch 72/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3711\n",
      "Epoch 73/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3731\n",
      "Epoch 74/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3765\n",
      "Epoch 75/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3764\n",
      "Epoch 76/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3720\n",
      "Epoch 77/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3700\n",
      "Epoch 78/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3764\n",
      "Epoch 79/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3723\n",
      "Epoch 80/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3661\n",
      "Epoch 81/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3734\n",
      "Epoch 82/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3679\n",
      "Epoch 83/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3657\n",
      "Epoch 84/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3716\n",
      "Epoch 85/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3649\n",
      "Epoch 86/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3676\n",
      "Epoch 87/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3646\n",
      "Epoch 88/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3671\n",
      "Epoch 89/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3655\n",
      "Epoch 90/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3590\n",
      "Epoch 91/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3599\n",
      "Epoch 92/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3502\n",
      "Epoch 93/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3523\n",
      "Epoch 94/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3380\n",
      "Epoch 95/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3401\n",
      "Epoch 96/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3320\n",
      "Epoch 97/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3304\n",
      "Epoch 98/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3261\n",
      "Epoch 99/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3248\n",
      "Epoch 100/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3179\n",
      "Epoch 101/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3148\n",
      "Epoch 102/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3134\n",
      "Epoch 103/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3127\n",
      "Epoch 104/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3137\n",
      "Epoch 105/200\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3102\n",
      "Epoch 106/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3038\n",
      "Epoch 107/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3069\n",
      "Epoch 108/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3031\n",
      "Epoch 109/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3024\n",
      "Epoch 110/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3001\n",
      "Epoch 111/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2960\n",
      "Epoch 112/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2973\n",
      "Epoch 113/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3008\n",
      "Epoch 114/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2970\n",
      "Epoch 115/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2951\n",
      "Epoch 116/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2956\n",
      "Epoch 117/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2974\n",
      "Epoch 118/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2927\n",
      "Epoch 119/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2895\n",
      "Epoch 120/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2961\n",
      "Epoch 121/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2898\n",
      "Epoch 122/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2881\n",
      "Epoch 123/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2935\n",
      "Epoch 124/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2860\n",
      "Epoch 125/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2955\n",
      "Epoch 126/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2947\n",
      "Epoch 127/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2879\n",
      "Epoch 128/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2944\n",
      "Epoch 129/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2900\n",
      "Epoch 130/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2893\n",
      "Epoch 131/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2881\n",
      "Epoch 132/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2825\n",
      "Epoch 133/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2897\n",
      "Epoch 134/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2847\n",
      "Epoch 135/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2824\n",
      "Epoch 136/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2886\n",
      "Epoch 137/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2843\n",
      "Epoch 138/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2824\n",
      "Epoch 139/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2852\n",
      "Epoch 140/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2848\n",
      "Epoch 141/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2872\n",
      "Epoch 142/200\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2833\n",
      "Epoch 143/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2791\n",
      "Epoch 144/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2824\n",
      "Epoch 145/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2856\n",
      "Epoch 146/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2829\n",
      "Epoch 147/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2901\n",
      "Epoch 148/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2839\n",
      "Epoch 149/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2764\n",
      "Epoch 150/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2865\n",
      "Epoch 151/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2769\n",
      "Epoch 152/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2767\n",
      "Epoch 153/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2811\n",
      "Epoch 154/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2799\n",
      "Epoch 155/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2828\n",
      "Epoch 156/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2861\n",
      "Epoch 157/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2833\n",
      "Epoch 158/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2760\n",
      "Epoch 159/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2790\n",
      "Epoch 160/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2808\n",
      "Epoch 161/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2814\n",
      "Epoch 162/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2808\n",
      "Epoch 163/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2818\n",
      "Epoch 164/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2807\n",
      "Epoch 165/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2749\n",
      "Epoch 166/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2802\n",
      "Epoch 167/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2715\n",
      "Epoch 168/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2774\n",
      "Epoch 169/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2768\n",
      "Epoch 170/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2737\n",
      "Epoch 171/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2723\n",
      "Epoch 172/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2743\n",
      "Epoch 173/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2732\n",
      "Epoch 174/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2823\n",
      "Epoch 175/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2745\n",
      "Epoch 176/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2786\n",
      "Epoch 177/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2738\n",
      "Epoch 178/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2746\n",
      "Epoch 179/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2736\n",
      "Epoch 180/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2732\n",
      "Epoch 181/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2702\n",
      "Epoch 182/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2750\n",
      "Epoch 183/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2744\n",
      "Epoch 184/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2722\n",
      "Epoch 185/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2730\n",
      "Epoch 186/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2737\n",
      "Epoch 187/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2782\n",
      "Epoch 188/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2723\n",
      "Epoch 189/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2744\n",
      "Epoch 190/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2810\n",
      "Epoch 191/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2736\n",
      "Epoch 192/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2765\n",
      "Epoch 193/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2726\n",
      "Epoch 194/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2670\n",
      "Epoch 195/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2746\n",
      "Epoch 196/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2702\n",
      "Epoch 197/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2712\n",
      "Epoch 198/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2724\n",
      "Epoch 199/200\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2741\n",
      "Epoch 200/200\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2687\n",
      "463/463 [==============================] - 1s 2ms/step\n",
      "Mean Squared Error: 4.23765857209698\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Prepare your data (X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Build your regression model\n",
    "model = keras.Sequential([\n",
    "   \n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(8,)),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train your model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32,verbose = 1)\n",
    "\n",
    "# Evaluate your model\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "tb['TF64:150'] = mse\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3a7c9fd-ce84-480b-b02d-73ebc5892dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.23765857209698\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5065aba-a05d-42e4-9cd2-9714cbca747f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1852/1852 [==============================] - 7s 3ms/step - loss: 10.1779\n",
      "Epoch 2/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 5.1146\n",
      "Epoch 3/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.6559\n",
      "Epoch 4/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5597\n",
      "Epoch 5/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5256\n",
      "Epoch 6/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4956\n",
      "Epoch 7/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4713\n",
      "Epoch 8/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4532\n",
      "Epoch 9/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4296\n",
      "Epoch 10/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4176\n",
      "Epoch 11/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3953\n",
      "Epoch 12/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3854\n",
      "Epoch 13/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3818\n",
      "Epoch 14/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3611\n",
      "Epoch 15/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3605\n",
      "Epoch 16/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3569\n",
      "Epoch 17/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3496\n",
      "Epoch 18/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3338\n",
      "Epoch 19/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3365\n",
      "Epoch 20/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3292\n",
      "Epoch 21/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3305\n",
      "Epoch 22/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3308\n",
      "Epoch 23/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3311\n",
      "Epoch 24/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3205\n",
      "Epoch 25/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3254\n",
      "Epoch 26/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3113\n",
      "Epoch 27/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3146\n",
      "Epoch 28/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3161\n",
      "Epoch 29/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3153\n",
      "Epoch 30/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3116\n",
      "Epoch 31/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3068\n",
      "Epoch 32/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3110\n",
      "Epoch 33/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.3056\n",
      "Epoch 34/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3075\n",
      "Epoch 35/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3054\n",
      "Epoch 36/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3050\n",
      "Epoch 37/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3038\n",
      "Epoch 38/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3024\n",
      "Epoch 39/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2989\n",
      "Epoch 40/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3028\n",
      "Epoch 41/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2986\n",
      "Epoch 42/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3021\n",
      "Epoch 43/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2920\n",
      "Epoch 44/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2976\n",
      "Epoch 45/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2941\n",
      "Epoch 46/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2921\n",
      "Epoch 47/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2939\n",
      "Epoch 48/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2908\n",
      "Epoch 49/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2893\n",
      "Epoch 50/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2946\n",
      "Epoch 51/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2890\n",
      "Epoch 52/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2800\n",
      "Epoch 53/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2902\n",
      "Epoch 54/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2881\n",
      "Epoch 55/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2943\n",
      "Epoch 56/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2880\n",
      "Epoch 57/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2865\n",
      "Epoch 58/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2873\n",
      "Epoch 59/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2915\n",
      "Epoch 60/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2820\n",
      "Epoch 61/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2860\n",
      "Epoch 62/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2877\n",
      "Epoch 63/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2822\n",
      "Epoch 64/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2825\n",
      "Epoch 65/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2820\n",
      "Epoch 66/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2855\n",
      "Epoch 67/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2847\n",
      "Epoch 68/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2876\n",
      "Epoch 69/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2779\n",
      "Epoch 70/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2821\n",
      "Epoch 71/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2749\n",
      "Epoch 72/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2768\n",
      "Epoch 73/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2763\n",
      "Epoch 74/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2756\n",
      "Epoch 75/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2737\n",
      "Epoch 76/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2758\n",
      "Epoch 77/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2727\n",
      "Epoch 78/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2777\n",
      "Epoch 79/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2767\n",
      "Epoch 80/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.2749\n",
      "Epoch 81/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2700\n",
      "Epoch 82/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2732\n",
      "Epoch 83/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.2744\n",
      "Epoch 84/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2723\n",
      "Epoch 85/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2723\n",
      "Epoch 86/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2710\n",
      "Epoch 87/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2756\n",
      "Epoch 88/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2706\n",
      "Epoch 89/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2723\n",
      "Epoch 90/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2671\n",
      "Epoch 91/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2686\n",
      "Epoch 92/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2728\n",
      "Epoch 93/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2717\n",
      "Epoch 94/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.2771\n",
      "Epoch 95/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2696\n",
      "Epoch 96/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2657\n",
      "Epoch 97/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2697\n",
      "Epoch 98/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2657\n",
      "Epoch 99/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2679\n",
      "Epoch 100/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.2668\n",
      "463/463 [==============================] - 1s 2ms/step\n",
      "Mean Squared Error: 4.2687707529963195\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Prepare your data (X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Build your regression model\n",
    "model1 = keras.Sequential([\n",
    "   \n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(8,)),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train your model\n",
    "history = model1.fit(X_train, y_train, epochs=100,verbose = 1)\n",
    "\n",
    "# Evaluate your model\n",
    "predictions = model1.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "tb[ 'Tensor128:50'] = mse\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebd5de68-a726-4818-81fb-327f4ef5a590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "470e4c05-a4f2-480b-a5a7-df67a42f1f75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 12.8534\n",
      "Epoch 2/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 5.6070\n",
      "Epoch 3/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 5.0835\n",
      "Epoch 4/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.7791\n",
      "Epoch 5/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.6812\n",
      "Epoch 6/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.6488\n",
      "Epoch 7/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.6343\n",
      "Epoch 8/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.6179\n",
      "Epoch 9/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.6050\n",
      "Epoch 10/100\n",
      "1852/1852 [==============================] - 6s 4ms/step - loss: 4.5924\n",
      "Epoch 11/100\n",
      "1852/1852 [==============================] - 8s 4ms/step - loss: 4.5846\n",
      "Epoch 12/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5798\n",
      "Epoch 13/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5672\n",
      "Epoch 14/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5629\n",
      "Epoch 15/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5582\n",
      "Epoch 16/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5491\n",
      "Epoch 17/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.5449\n",
      "Epoch 18/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5416\n",
      "Epoch 19/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5325\n",
      "Epoch 20/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5286\n",
      "Epoch 21/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5232\n",
      "Epoch 22/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5168\n",
      "Epoch 23/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.5086\n",
      "Epoch 24/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4988\n",
      "Epoch 25/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4921\n",
      "Epoch 26/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4859\n",
      "Epoch 27/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4801\n",
      "Epoch 28/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4691\n",
      "Epoch 29/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4680\n",
      "Epoch 30/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4624\n",
      "Epoch 31/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.4519\n",
      "Epoch 32/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4467\n",
      "Epoch 33/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.4445\n",
      "Epoch 34/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4350\n",
      "Epoch 35/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4326\n",
      "Epoch 36/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4323\n",
      "Epoch 37/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4263\n",
      "Epoch 38/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4214\n",
      "Epoch 39/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4168\n",
      "Epoch 40/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4168\n",
      "Epoch 41/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4138\n",
      "Epoch 42/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4099\n",
      "Epoch 43/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4093\n",
      "Epoch 44/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4115\n",
      "Epoch 45/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4040\n",
      "Epoch 46/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4047\n",
      "Epoch 47/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4099\n",
      "Epoch 48/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4030\n",
      "Epoch 49/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3964\n",
      "Epoch 50/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3973\n",
      "Epoch 51/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3971\n",
      "Epoch 52/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.4007\n",
      "Epoch 53/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3940\n",
      "Epoch 54/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4011\n",
      "Epoch 55/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3926\n",
      "Epoch 56/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.4006\n",
      "Epoch 57/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3891\n",
      "Epoch 58/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3917\n",
      "Epoch 59/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3915\n",
      "Epoch 60/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3869\n",
      "Epoch 61/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3946\n",
      "Epoch 62/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3838\n",
      "Epoch 63/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3916\n",
      "Epoch 64/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3866\n",
      "Epoch 65/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3902\n",
      "Epoch 66/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3901\n",
      "Epoch 67/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3829\n",
      "Epoch 68/100\n",
      "1852/1852 [==============================] - 5s 3ms/step - loss: 4.3886\n",
      "Epoch 69/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3824\n",
      "Epoch 70/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3840\n",
      "Epoch 71/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3873\n",
      "Epoch 72/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3880\n",
      "Epoch 73/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3811\n",
      "Epoch 74/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3836\n",
      "Epoch 75/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3855\n",
      "Epoch 76/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3775\n",
      "Epoch 77/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3784\n",
      "Epoch 78/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3797\n",
      "Epoch 79/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3815\n",
      "Epoch 80/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3816\n",
      "Epoch 81/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3822\n",
      "Epoch 82/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3842\n",
      "Epoch 83/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3798\n",
      "Epoch 84/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3779\n",
      "Epoch 85/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3741\n",
      "Epoch 86/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3758\n",
      "Epoch 87/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3747\n",
      "Epoch 88/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3731\n",
      "Epoch 89/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3733\n",
      "Epoch 90/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3748\n",
      "Epoch 91/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3733\n",
      "Epoch 92/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3739\n",
      "Epoch 93/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3797\n",
      "Epoch 94/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3789\n",
      "Epoch 95/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3735\n",
      "Epoch 96/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3748\n",
      "Epoch 97/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3746\n",
      "Epoch 98/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3709\n",
      "Epoch 99/100\n",
      "1852/1852 [==============================] - 6s 3ms/step - loss: 4.3781\n",
      "Epoch 100/100\n",
      "1852/1852 [==============================] - 7s 4ms/step - loss: 4.3727\n",
      "463/463 [==============================] - 1s 2ms/step\n",
      "Mean Squared Error: 4.361125744131471\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Prepare your data (X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Build your regression model\n",
    "model12 = keras.Sequential([\n",
    "   \n",
    "    keras.layers.Dense(32, activation='relu', input_shape=(8,)),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model12.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train your model\n",
    "history = model12.fit(X_train, y_train, epochs=100,verbose = 1)\n",
    "\n",
    "# Evaluate your model\n",
    "predictions = model12.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "tb[ 'Tensor128:50'] = mse\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d8dc8dc-bcd6-4e2a-a6f3-21529087592f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97323749-f1d8-4041-b611-94696e049c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dee532-ff2d-4085-baac-8536f0e0358e",
   "metadata": {},
   "source": [
    "# TESTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "225ba1b7-65ba-46d5-9a3f-eb2e3cb57a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pf = pd.read_csv('test.csv',index_col = 'id')\n",
    "pf['Sex'] = pf['Sex'].map({'M' : 1,  'I':2, 'F':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e66eb977-b3f8-46c2-9efd-c9b7f316ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543/1543 [==============================] - 3s 2ms/step\n",
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(pf)\n",
    "X = pd.DataFrame(scaler.transform(pf), columns=pf.columns)\n",
    "Age = model1.predict(X)\n",
    "sf = pd.read_csv('sample_submission.csv',index_col = 'id')\n",
    "sf['Age'] = Age\n",
    "gfg_csv_data = sf.to_csv('SEND10.csv', index = True)\n",
    "print('\\nCSV String:\\n', gfg_csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57374b6b-f50e-47bf-88dc-ddc871e8617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 4.6438687763992075,\n",
       " 'PolynomialFeatures': 4.301580752639548,\n",
       " 'Ridge': 4.644834308184121,\n",
       " 'lasso': 6.409514974338962,\n",
       " 'ElasticNet': 6.93300346181345,\n",
       " 'DecisionTreeRegressor': 8.514077374924042,\n",
       " 'RandomForestRegressor': 4.356784191331612,\n",
       " 'GradientBoostingRegressor': 4.159428243633231,\n",
       " 'BayesianRidge': 4.643900746833225,\n",
       " 'PassiveAggressiveRegressor': 9.953226743474952,\n",
       " 'OrthogonalMatchingPursuit': 6.24413119272728,\n",
       " 'RANSACRegressor': 6.6810809790051255,\n",
       " 'HuberRegressor': 4.795631576242048,\n",
       " 'TheilSenRegressor': 4.705804062162434,\n",
       " 'ARDRegression': 4.644759225794523,\n",
       " 'ARDRegrPassiveAggressiveClassifieression': 6.295321045169131,\n",
       " 'PoissonRegressor': 7.15210770184293,\n",
       " 'Lars': 4.64386877639921,\n",
       " 'RidgeCV': 4.64402220125446,\n",
       " 'TF64:150': 4.23765857209698,\n",
       " 'Tensor128:50': 4.2687707529963195}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python code demonstrate creating\n",
    "# DataFrame from dict narray / lists\n",
    "# By default addresses.\n",
    "\n",
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0eb4d6-ced6-4d19-9e8a-16f5aa052528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8848c2-c41c-4508-91de-5224739a9997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bankai",
   "language": "python",
   "name": "bankai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
